{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JoJoGAN",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cedro3/JoJoGAN/blob/main/JoJoGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# JoJoGAN: ワンショット顔スタイル変換"
      ],
      "metadata": {
        "id": "k_sHBJLwE6-s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F50ju05EgX_B",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title セットアップ\n",
        "!git clone https://github.com/cedro3/JoJoGAN.git\n",
        "%cd JoJoGAN\n",
        "!pip install tqdm gdown scikit-learn==0.22 scipy lpips dlib opencv-python wandb\n",
        "!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
        "!sudo unzip ninja-linux.zip -d /usr/local/bin/\n",
        "!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import torch\n",
        "torch.backends.cudnn.benchmark = True\n",
        "from torchvision import transforms, utils\n",
        "from util import *\n",
        "from PIL import Image\n",
        "import math\n",
        "import random\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "from torch import nn, autograd, optim\n",
        "from torch.nn import functional as F\n",
        "from tqdm import tqdm\n",
        "import lpips\n",
        "import wandb\n",
        "from model import *\n",
        "from e4e_projection import projection as e4e_projection\n",
        "\n",
        "from google.colab import files\n",
        "from copy import deepcopy\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "os.makedirs('inversion_codes', exist_ok=True)\n",
        "os.makedirs('style_images', exist_ok=True)\n",
        "os.makedirs('style_images_aligned', exist_ok=True)\n",
        "os.makedirs('models', exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "# Download models\n",
        "#markdown You may optionally enable downloads with pydrive in order to authenticate and avoid drive download limits.\n",
        "download_with_pydrive = False #param {type:\"boolean\"}    \n",
        "device = 'cuda' #param ['cuda', 'cpu']\n",
        "\n",
        "!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
        "!bzip2 -dk shape_predictor_68_face_landmarks.dat.bz2\n",
        "!mv shape_predictor_68_face_landmarks.dat models/dlibshape_predictor_68_face_landmarks.dat\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "drive_ids = {\n",
        "    \"stylegan2-ffhq-config-f.pt\": \"1Yr7KuD959btpmcKGAUsbAk5rPjX2MytK\",\n",
        "    \"e4e_ffhq_encode.pt\": \"1o6ijA3PkcewZvwJJ73dJ0fxhndn0nnh7\",\n",
        "    \"restyle_psp_ffhq_encode.pt\": \"1nbxCIVw9H3YnQsoIPykNEFwWJnHVHlVd\",\n",
        "    \"arcane_caitlyn.pt\": \"1gOsDTiTPcENiFOrhmkkxJcTURykW1dRc\",\n",
        "    \"arcane_caitlyn_preserve_color.pt\": \"1cUTyjU-q98P75a8THCaO545RTwpVV-aH\",\n",
        "    \"arcane_jinx_preserve_color.pt\": \"1jElwHxaYPod5Itdy18izJk49K1nl4ney\",\n",
        "    \"arcane_jinx.pt\": \"1quQ8vPjYpUiXM4k1_KIwP4EccOefPpG_\",\n",
        "    \"arcane_multi_preserve_color.pt\": \"1enJgrC08NpWpx2XGBmLt1laimjpGCyfl\",\n",
        "    \"arcane_multi.pt\": \"15V9s09sgaw-zhKp116VHigf5FowAy43f\",\n",
        "    \"disney.pt\": \"1zbE2upakFUAx8ximYnLofFwfT8MilqJA\",\n",
        "    \"disney_preserve_color.pt\": \"1Bnh02DjfvN_Wm8c4JdOiNV4q9J7Z_tsi\",\n",
        "    \"jojo.pt\": \"13cR2xjIBj8Ga5jMO7gtxzIJj2PDsBYK4\",\n",
        "    \"jojo_preserve_color.pt\": \"1ZRwYLRytCEKi__eT2Zxv1IlV6BGVQ_K2\",\n",
        "    \"jojo_yasuho.pt\": \"1grZT3Gz1DLzFoJchAmoj3LoM9ew9ROX_\",\n",
        "    \"jojo_yasuho_preserve_color.pt\": \"1SKBu1h0iRNyeKBnya_3BBmLr4pkPeg_L\",\n",
        "    \"supergirl.pt\": \"1L0y9IYgzLNzB-33xTpXpecsKU-t9DpVC\",\n",
        "    \"supergirl_preserve_color.pt\": \"1VmKGuvThWHym7YuayXxjv0fSn32lfDpE\",\n",
        "    \"art.pt\": \"1a0QDEHwXQ6hE_FcYEyNMuv5r5UnRQLKT\",\n",
        "}\n",
        "\n",
        "# from StyelGAN-NADA\n",
        "class Downloader(object):\n",
        "    def __init__(self, use_pydrive):\n",
        "        self.use_pydrive = use_pydrive\n",
        "\n",
        "        if self.use_pydrive:\n",
        "            self.authenticate()\n",
        "        \n",
        "    def authenticate(self):\n",
        "        auth.authenticate_user()\n",
        "        gauth = GoogleAuth()\n",
        "        gauth.credentials = GoogleCredentials.get_application_default()\n",
        "        self.drive = GoogleDrive(gauth)\n",
        "    \n",
        "    def download_file(self, file_name):\n",
        "        file_dst = os.path.join('models', file_name)\n",
        "        file_id = drive_ids[file_name]\n",
        "        if not os.path.exists(file_dst):\n",
        "            print(f'Downloading {file_name}')\n",
        "            if self.use_pydrive:\n",
        "                downloaded = self.drive.CreateFile({'id':file_id})\n",
        "                downloaded.FetchMetadata(fetch_all=True)\n",
        "                downloaded.GetContentFile(file_dst)\n",
        "            else:\n",
        "                !gdown --id $file_id -O $file_dst\n",
        "\n",
        "\n",
        "\n",
        "downloader = Downloader(download_with_pydrive)\n",
        "\n",
        "downloader.download_file('stylegan2-ffhq-config-f.pt')\n",
        "downloader.download_file('e4e_ffhq_encode.pt')\n",
        "\n",
        "latent_dim = 512\n",
        "\n",
        "# Load original generator\n",
        "original_generator = Generator(1024, latent_dim, 8, 2).to(device)\n",
        "ckpt = torch.load('models/stylegan2-ffhq-config-f.pt', map_location=lambda storage, loc: storage)\n",
        "original_generator.load_state_dict(ckpt[\"g_ema\"], strict=False)\n",
        "mean_latent = original_generator.mean_latent(10000)\n",
        "\n",
        "# to be finetuned generator\n",
        "generator = deepcopy(original_generator)\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((1024, 1024)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "# --- 画像表示関数 ---\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "def display_pic(folder):\n",
        "    fig = plt.figure(figsize=(20, 40))\n",
        "    files = os.listdir(folder)\n",
        "    files.sort()\n",
        "    for i, file in enumerate(files):\n",
        "        if file=='.ipynb_checkpoints':\n",
        "           continue\n",
        "        img = Image.open(folder+'/'+file)    \n",
        "        images = np.asarray(img)\n",
        "        ax = fig.add_subplot(10, 5, i+1, xticks=[], yticks=[])\n",
        "        image_plt = np.array(images)\n",
        "        ax.imshow(image_plt)\n",
        "        ax.set_xlabel(file, fontsize=20)               \n",
        "    plt.show()\n",
        "    plt.close() \n",
        "\n",
        "\n",
        "# --- 画像編集 ---\n",
        "from PIL import Image\n",
        "def get_concat_h(im1, im2):\n",
        "    dst = Image.new('RGB', (im1.width + im2.width, im1.height))\n",
        "    dst.paste(im1, (0, 0))\n",
        "    dst.paste(im2, (im1.width, 0))\n",
        "    return dst\n",
        "\n",
        "def get_concat_v(im1, im2):\n",
        "    dst = Image.new('RGB', (im1.width, im1.height + im2.height))\n",
        "    dst.paste(im1, (0, 0))\n",
        "    dst.paste(im2, (0, im1.height))\n",
        "    return dst\n",
        "\n",
        "def edit_pic(file_path):\n",
        "    im = Image.open(file_path)\n",
        "    black = Image.open('./black.jpg')\n",
        "    im_a = im.crop((0, 0, 1028, 1028))\n",
        "    im_b = im.crop((1028,0,3080,1028))\n",
        "    up = get_concat_h(black, im_a)\n",
        "    get_concat_v(up, im_b).save(file_path)\n",
        "\n",
        "\n",
        "import os\n",
        "os.makedirs('pic', exist_ok=True) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 学習済みモデルによるスタイル変換"
      ],
      "metadata": {
        "id": "IiTyrF2odnt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title サンプル画像の表示\n",
        "display_pic('pic')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "6x3lDQMc6XMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title サンプル画像のalignと潜在変数取得\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# alignフォルダーリセット\n",
        "if os.path.isdir('align'):\n",
        "    shutil.rmtree('align')\n",
        "os.makedirs('align', exist_ok=True)\n",
        "\n",
        "# vectorsフォルダーリセット\n",
        "if os.path.isdir('vectors'):\n",
        "    shutil.rmtree('vectors')\n",
        "os.makedirs('vectors', exist_ok=True)\n",
        "\n",
        "# picフォルダの画像をalignし、alignフォルダに保存\n",
        "files = sorted(os.listdir('./pic'))\n",
        "for file in files:\n",
        "    if file=='.ipynb_checkpoints':\n",
        "      continue\n",
        "    aligned_face = align_face('./pic/'+file)\n",
        "    aligned_face.save('./align/'+file)\n",
        "\n",
        "# alignフォルダの画像の潜在変数を求め、vectorsフォルダに保存\n",
        "files = sorted(os.listdir('./align'))\n",
        "for file in files:\n",
        "    if file=='.ipynb_checkpoints':\n",
        "      continue  \n",
        "    aligned_face = Image.open('./align/'+file) \n",
        "    name = './vectors/'+os.path.splitext(file)[0]+'.pt'    \n",
        "    my_w = e4e_projection(aligned_face, name, device).unsqueeze(0)\n",
        "\n",
        "display_pic('align')"
      ],
      "metadata": {
        "id": "luVbnxAQv8js",
        "collapsed": true,
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title スタイル変換\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "# resultsフォルダーリセット\n",
        "if os.path.isdir('results'):\n",
        "    shutil.rmtree('results')\n",
        "os.makedirs('results', exist_ok=True)\n",
        "\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "\n",
        "pretrained = 'jojo' #@param ['art', 'arcane_multi', 'supergirl', 'arcane_jinx', 'arcane_caitlyn', 'jojo_yasuho', 'jojo', 'disney']\n",
        "preserve_color = True #@param{type:\"boolean\"}\n",
        "if preserve_color:\n",
        "    ckpt = f'{pretrained}_preserve_color.pt'\n",
        "else:\n",
        "    ckpt = f'{pretrained}.pt'\n",
        "\n",
        "# load base version if preserve_color version not available\n",
        "try:\n",
        "    downloader.download_file(ckpt)\n",
        "except:\n",
        "    ckpt = f'{pretrained}.pt'\n",
        "    downloader.download_file(ckpt)\n",
        "\n",
        "ckpt = torch.load(os.path.join('models', ckpt), map_location=lambda storage, loc: storage)\n",
        "generator.load_state_dict(ckpt[\"g\"], strict=False)\n",
        "\n",
        "#model_path = 'model.pth'\n",
        "#generator.load_state_dict(torch.load(model_path))\n",
        "\n",
        "def conversion(file):\n",
        "    with torch.no_grad():\n",
        "        generator.eval()\n",
        "        my_w = torch.load('./vectors/'+os.path.splitext(file)[0]+'.pt')['latent'].reshape(1,18,512)\n",
        "        original_my_sample = original_generator(my_w, input_is_latent=True)\n",
        "        my_sample = generator(my_w, input_is_latent=True)\n",
        "\n",
        "    # display reference images\n",
        "    if pretrained == 'arcane_multi':\n",
        "        style_path = f'style_images_aligned/arcane_jinx.png'\n",
        "    else:   \n",
        "        style_path = f'style_images_aligned/{pretrained}.png'\n",
        "    style_image = transform(Image.open(style_path)).unsqueeze(0).to(device)\n",
        "\n",
        "    aligned_face = Image.open('./align/'+file)\n",
        "    face = transform(aligned_face).unsqueeze(0).to(device)\n",
        "\n",
        "    my_output = torch.cat([style_image, face, my_sample], 0)\n",
        "    x = utils.make_grid(my_output, normalize=True, range=(-1, 1))\n",
        "    display_image(utils.make_grid(x))\n",
        "    img = torchvision.transforms.functional.to_pil_image(x)\n",
        "    img.save('./results/'+file)\n",
        "\n",
        "# 変換\n",
        "files = sorted(os.listdir('./align'))\n",
        "for file in files:\n",
        "    if file=='.ipynb_checkpoints':\n",
        "      continue\n",
        "    conversion(file)"
      ],
      "metadata": {
        "id": "FKBP5bVx8fCx",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 動画の作成\n",
        "\n",
        "# tmpフォルダーリセット\n",
        "if os.path.isdir('tmp'):\n",
        "    shutil.rmtree('tmp')\n",
        "os.makedirs('tmp', exist_ok=True)\n",
        "\n",
        "# output.mp4をリセット\n",
        "if os.path.exists('./output.mp4'):\n",
        "   os.remove('./output.mp4')\n",
        "\n",
        "# resultsフォルダのファイルを連番画像にしてtmpフォルダへ保存\n",
        "files = sorted(os.listdir('results'))\n",
        "count = 0\n",
        "for file in files:\n",
        "    if file=='.ipynb_checkpoints':\n",
        "      continue\n",
        "    shutil.copy('./results/'+file, './tmp/'+str(count).zfill(6)+'.jpg')\n",
        "    edit_pic('./tmp/'+str(count).zfill(6)+'.jpg')\n",
        "    count +=1\n",
        "\n",
        "# 連番画像をmp4に変換\n",
        "!ffmpeg -r 1 -i tmp/%6d.jpg -vcodec libx264 -pix_fmt yuv420p -loglevel error output.mp4\n",
        "\n",
        "# 動画の再生\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "mp4 = open('./output.mp4', 'rb').read()\n",
        "data_url = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"\n",
        "<video width=\"70%\" height=\"70%\" controls>\n",
        "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "</video>\"\"\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "UCNpyKphS0uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ワンショット学習によるスタイル変換"
      ],
      "metadata": {
        "id": "VZdYrfVcJdqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title スタイル画像表示\n",
        "display_pic('style_images')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "OWcp5Kyn4XXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title スタイル画像のalignと潜在変数の取得\n",
        "names = ['001.jpg'] #@param {type:\"raw\"}\n",
        "\n",
        "targets = []\n",
        "latents = []\n",
        "\n",
        "for name in names:\n",
        "    style_path = os.path.join('style_images', name)\n",
        "    assert os.path.exists(style_path), f\"{style_path} does not exist!\"\n",
        "\n",
        "    name = strip_path_extension(name)\n",
        "\n",
        "    # crop and align the face\n",
        "    style_aligned_path = os.path.join('style_images_aligned', f'{name}.png')\n",
        "    if not os.path.exists(style_aligned_path):\n",
        "        style_aligned = align_face(style_path)\n",
        "        style_aligned.save(style_aligned_path)\n",
        "    else:\n",
        "        style_aligned = Image.open(style_aligned_path).convert('RGB')\n",
        "\n",
        "    # GAN invert\n",
        "    style_code_path = os.path.join('inversion_codes', f'{name}.pt')\n",
        "    if not os.path.exists(style_code_path):\n",
        "        latent = e4e_projection(style_aligned, style_code_path, device)\n",
        "    else:\n",
        "        latent = torch.load(style_code_path)['latent']\n",
        "\n",
        "    targets.append(transform(style_aligned).to(device))\n",
        "    latents.append(latent.to(device))\n",
        "\n",
        "targets = torch.stack(targets, 0)\n",
        "latents = torch.stack(latents, 0)\n",
        "\n",
        "target_im = utils.make_grid(targets, normalize=True, range=(-1, 1))\n",
        "display_image(target_im, title='Style References')"
      ],
      "metadata": {
        "id": "hgfk78K1ikb8",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ファインチューニング\n",
        "alpha =  1.0 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "alpha = 1-alpha\n",
        "preserve_color = True #@param{type:\"boolean\"}\n",
        "num_iter = 200 #@param {type:\"number\"}\n",
        "#log_interval = 50 #@param {type:\"number\"}\n",
        "\n",
        "lpips_fn = lpips.LPIPS(net='vgg').to(device)\n",
        "\n",
        "# reset generator\n",
        "del generator\n",
        "generator = deepcopy(original_generator)\n",
        "g_optim = optim.Adam(generator.parameters(), lr=2e-3, betas=(0, 0.99))\n",
        "\n",
        "# Which layers to swap for generating a family of plausible real images -> fake image\n",
        "if preserve_color:\n",
        "    id_swap = [7,9,11,15,16,17]\n",
        "else:\n",
        "    id_swap = list(range(7, generator.n_latent))\n",
        "\n",
        "for idx in tqdm(range(num_iter)):\n",
        "    if preserve_color:\n",
        "        random_alpha = 0\n",
        "    else:\n",
        "        random_alpha = np.random.uniform(alpha, 1)\n",
        "    mean_w = generator.get_latent(torch.randn([latents.size(0), latent_dim]).to(device)).unsqueeze(1).repeat(1, generator.n_latent, 1)\n",
        "    in_latent = latents.clone()\n",
        "    in_latent[:, id_swap] = alpha*latents[:, id_swap] + (1-alpha)*mean_w[:, id_swap]\n",
        "\n",
        "    img = generator(in_latent, input_is_latent=True)\n",
        "    loss = lpips_fn(F.interpolate(img, size=(256,256), mode='area'), F.interpolate(targets, size=(256,256), mode='area')).mean()\n",
        "    \n",
        "    g_optim.zero_grad()\n",
        "    loss.backward()\n",
        "    g_optim.step()\n",
        "\n",
        "# パラメータ保存\n",
        "torch.save(generator.state_dict(), 'model.pth')"
      ],
      "metadata": {
        "id": "_qNPut_ch3gr",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title スタイル変換\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "# resultsフォルダーリセット\n",
        "if os.path.isdir('results'):\n",
        "    shutil.rmtree('results')\n",
        "os.makedirs('results', exist_ok=True)\n",
        "\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "\n",
        "# display reference images\n",
        "style_images = []\n",
        "for name in names:\n",
        "    style_path = f'style_images_aligned/{strip_path_extension(name)}.png'\n",
        "    style_image = transform(Image.open(style_path))\n",
        "    style_images.append(style_image)\n",
        "    \n",
        "style_images = torch.stack(style_images, 0).to(device)\n",
        "display_image(utils.make_grid(style_images, normalize=True, range=(-1, 1)), title='References')\n",
        "\n",
        "\n",
        "# model.pth ロード\n",
        "generator.load_state_dict(torch.load('model.pth'))\n",
        "\n",
        "def conversion(file):\n",
        "    with torch.no_grad():\n",
        "        generator.eval()\n",
        "        my_w = torch.load('./vectors/'+os.path.splitext(file)[0]+'.pt')['latent'].reshape(1,18,512)\n",
        "        original_my_sample = original_generator(my_w, input_is_latent=True)\n",
        "        my_sample = generator(my_w, input_is_latent=True)\n",
        "\n",
        "    aligned_face = Image.open('./align/'+file)\n",
        "    face = transform(aligned_face).unsqueeze(0).to(device)\n",
        "\n",
        "    file_path = os.path.splitext('./style_images_aligned/'+names[0])[0]+'.png'\n",
        "    reference = transform(Image.open(file_path)).unsqueeze(0).to(device)\n",
        "\n",
        "    my_output = torch.cat([reference, face, my_sample], 0)\n",
        "    x = utils.make_grid(my_output, normalize=True, range=(-1, 1))\n",
        "    display_image(utils.make_grid(x))\n",
        "    img = torchvision.transforms.functional.to_pil_image(x)\n",
        "    img.save('./results/'+file)\n",
        "\n",
        "# 変換\n",
        "files = sorted(os.listdir('./align'))\n",
        "for file in files:\n",
        "    if file=='.ipynb_checkpoints':\n",
        "      continue\n",
        "    conversion(file)"
      ],
      "metadata": {
        "id": "emh-rCnF2e41",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 動画の作成\n",
        "# tmpフォルダーリセット\n",
        "if os.path.isdir('tmp'):\n",
        "    shutil.rmtree('tmp')\n",
        "os.makedirs('tmp', exist_ok=True)\n",
        "\n",
        "# output.mp4をリセット\n",
        "if os.path.exists('./output.mp4'):\n",
        "   os.remove('./output.mp4')\n",
        "\n",
        "# resultsフォルダのファイルを連番画像にしてtmpフォルダへ保存\n",
        "files = sorted(os.listdir('results'))\n",
        "count = 0\n",
        "for file in files:\n",
        "    if file=='.ipynb_checkpoints':\n",
        "      continue\n",
        "    shutil.copy('./results/'+file, './tmp/'+str(count).zfill(6)+'.jpg')\n",
        "    edit_pic('./tmp/'+str(count).zfill(6)+'.jpg')\n",
        "    count +=1\n",
        "\n",
        "# 連番画像をmp4に変換\n",
        "!ffmpeg -r 1 -i tmp/%6d.jpg -vcodec libx264 -pix_fmt yuv420p -loglevel error output.mp4\n",
        "\n",
        "# 動画の再生\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "mp4 = open('./output.mp4', 'rb').read()\n",
        "data_url = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"\n",
        "<video width=\"70%\" height=\"70%\" controls>\n",
        "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "</video>\"\"\")"
      ],
      "metadata": {
        "id": "-Odnyq679SPA",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}